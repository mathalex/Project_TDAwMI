{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dc9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nibabel.loadsave import ImageFileError\n",
    "\n",
    "from nilearn.image import load_img\n",
    "from nilearn import datasets\n",
    "from nilearn.maskers import NiftiMasker, NiftiLabelsMasker\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from nilearn import plotting\n",
    "\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import spearmanr, entropy\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d, uniform_filter1d, maximum_filter1d, minimum_filter1d\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.linalg import logm\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753798b",
   "metadata": {},
   "source": [
    "**Getting timeseries from fMRI scans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75df039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = datasets.fetch_atlas_aal()\n",
    "atlas_filename = atlas.maps\n",
    "atlas_labels = atlas.labels\n",
    "masker = NiftiLabelsMasker(atlas_filename, detrend=False)\n",
    "\n",
    "def get_time_series(path):\n",
    "    # print(path)\n",
    "    if not os.path.isfile(path):\n",
    "        return None\n",
    "    try:\n",
    "        fmri_img = load_img(path)\n",
    "    except ImageFileError:  # no run for session\n",
    "        return None\n",
    "    \n",
    "    time_series = masker.fit_transform(fmri_img)\n",
    "    time_series = StandardScaler().fit_transform(time_series[:, :])\n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad67c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_by_info(subj_id, session_id, run_id):\n",
    "    return get_time_series(f'./raw/timeseries/subj0{subj_id}/timeseries_session{session_id:02d}_run{run_id:02d}.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e4744c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c622cece98c4b0e9d0c4304fd5a1857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting timeseries:   0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SUBJ_IDS = (2,)  # need range(1, 8+1) --- download\n",
    "SESSION_IDS = range(1, 37+1)  # need range(1, 37+1) --- download, or use range(1, 23+1)\n",
    "RUN_IDS = range(1, 14+1)  # need range(1, 14+1) --- check 13 and 14 - may be empty\n",
    "\n",
    "trend_size = 50\n",
    "\n",
    "T = []\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for subj_id, session_id, run_id in tqdm(itertools.product(SUBJ_IDS, SESSION_IDS, RUN_IDS),\n",
    "                                        total=len(SUBJ_IDS) * len(SESSION_IDS) * len(RUN_IDS),\n",
    "                                        desc='Getting timeseries'):\n",
    "    time_series = get_ts_by_info(subj_id, session_id, run_id)\n",
    "    if time_series is None:\n",
    "        continue\n",
    "    \n",
    "    # get trend and subtract it\n",
    "    time_series_trend = uniform_filter1d(time_series, trend_size, axis=0)\n",
    "    time_series_filtered = time_series - time_series_trend\n",
    "                        \n",
    "    # standardize\n",
    "    time_series_std = StandardScaler().fit_transform(time_series)\n",
    "    time_series_filtered_std = StandardScaler().fit_transform(time_series_filtered)\n",
    "                        \n",
    "    # get connectivity matrices\n",
    "    A_raw = ConnectivityMeasure(kind=\"correlation\").fit_transform([time_series_std])[0]\n",
    "    A_filtered = ConnectivityMeasure(kind=\"correlation\").fit_transform([time_series_filtered_std])[0]\n",
    "    \n",
    "    # set data\n",
    "    T.append([time_series_std, time_series_filtered_std])\n",
    "    X.append([A_raw, A_filtered])\n",
    "    y.append(subj_id)\n",
    "T = np.array(T)\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da425c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"T_subjects_2_nsd_vs_rest.npy\", T)\n",
    "np.save(\"X_subjects_2_nsd_vs_rest.npy\", X)\n",
    "np.save(\"y_subjects_2_nsd_vs_rest.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133f52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 478\n",
    "n_steps = 226\n",
    "n_rois = 116\n",
    "\n",
    "# T = np.zeros((2 * n_trials, 2, n_steps, n_rois))\n",
    "# X = np.zeros((2 * n_trials, 2, n_rois, n_rois)) # subject, raw/filtered, matrix\n",
    "y_subjects = np.repeat([0, 1], n_trials)\n",
    "y_sessions = np.tile(np.concatenate([np.repeat(0, 240), np.repeat(1, 238)]), 2)\n",
    "y = np.concatenate([np.expand_dims(y_subjects, 0), np.expand_dims(y_sessions, 0)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c97ad436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((956, 2, 226, 116), (956, 2, 116, 116), (2, 956))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a30b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"T_subjects_1,5_nsd_vs_rest.npy\", T)\n",
    "np.save(\"X_subjects_1,5_nsd_vs_rest.npy\", X)\n",
    "np.save(\"y_subjects_1,5_nsd_vs_rest.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639f13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f82168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad2489e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((956, 2, 226, 116),\n",
       " (956, 2, 116, 116),\n",
       " (464, 2, 226, 116),\n",
       " (464, 2, 116, 116))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T15 = np.load(\"T_subjects_1,5_nsd_vs_rest.npy\")\n",
    "X15 = np.load(\"X_subjects_1,5_nsd_vs_rest.npy\")\n",
    "T2 = np.load(\"T_subjects_2_nsd_vs_rest.npy\")\n",
    "X2 = np.load(\"X_subjects_2_nsd_vs_rest.npy\")\n",
    "T15.shape, X15.shape, T2.shape, X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b048c89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1420, 2, 226, 116), (1420, 2, 116, 116), (1420,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T152 = np.concatenate((T15, T2))\n",
    "X152 = np.concatenate((X15, X2))\n",
    "y152 = np.concatenate((y15, y2))\n",
    "T152.shape, X152.shape, y152.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b704a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"T_subjects_152.npy\", T152)\n",
    "np.save(\"X_subjects_152.npy\", X152)\n",
    "np.save(\"y_subjects_152.npy\", y152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e0b21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((956,), (464,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y15 = np.load(\"y_subjects_1,5_nsd_vs_rest.npy\")[0]\n",
    "y2 = np.load(\"y_subjects_2_nsd_vs_rest.npy\")\n",
    "y15.shape, y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d345e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"y_subjects_152.npy\", y152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cb0ef95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y15[y15 == 1] = 5\n",
    "y15[y15 == 0] = 1\n",
    "y15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802fe5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8acf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load(\"y_subjects_152.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71602d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08db80a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJ_IDS = (1, 5, 2)  # need range(1, 8+1) --- download\n",
    "SESSION_IDS = range(1, 37+1)  # need range(1, 37+1) --- download, or use range(1, 23+1)\n",
    "\n",
    "y0 = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "\n",
    "for subj_id in SUBJ_IDS:\n",
    "    for session_id in SESSION_IDS:\n",
    "        if (subj_id in (1, 5) and session_id in range(21, 38+1)) or (subj_id not in (1, 5) and session_id in range(21, 30+1)):\n",
    "            y0 += [subj_id] * 14\n",
    "            y1 += [1] * 14\n",
    "            y2 += [1] + [0] * 12 + [1]\n",
    "        else:\n",
    "            y0 += [subj_id] * 12\n",
    "            y1 += [(0 if session_id <= 20 else 1)] * 12\n",
    "            y2 += [0] * 12\n",
    "y0 = np.array(y0)\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e43381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([y0, y1, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b05bdde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1420)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30dd1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual cortex\n",
    "visual = list(range(42, 53+1))\n",
    "# sensorimotor network, somatomotor network (SMN)\n",
    "smn = [0, 1, 6, 7, 18, 19, 56, 57, 62, 63, 68, 69]\n",
    "# ventral attention network (VAN), ventral frontoparietal network (VFN), ventral attention system (VAS)\n",
    "van = [32, 33, 34, 35, 36, 37, 52, 53, 62, 63, 64, 65]\n",
    "# default mode network (DMN), default network, default state network, medial frontoparietal network (M-FPN)\n",
    "dmn = [22, 23, 34, 35, 36, 37, 38, 39, 64, 65, 66, 67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6017f333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1420, 116, 116)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw = np.load(\"X_subjects_152.npy\")[:, 1]\n",
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3779dea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1420, 12, 12)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for brain_network in (visual, smn, van, dmn):\n",
    "    bn_idx = np.ix_(np.arange(0, X_raw.shape[0]), brain_network, brain_network)\n",
    "    X_bn = X_raw[bn_idx]\n",
    "    X.append(X_bn)\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8fae58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"corrs.npy\", X)\n",
    "np.save(\"labels.npy\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a927b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1420, 12, 12), (3, 1420))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4204e1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y[1] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ba5e9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1420,), (1420,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, y0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f43407db",
   "metadata": {},
   "outputs": [],
   "source": [
    "yz = np.load(\"y_subjects_1,5_nsd_vs_rest.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90a9ba4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 956)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d4da59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((956,), (956,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape, yz[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e465111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1 != yz[1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc702ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
